{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we'll going to learn, how to make scalable transformers and llms in a few lines of code."
      ],
      "metadata": {
        "id": "PMn4fvoJOx45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the Microsoft library: **torchscale**"
      ],
      "metadata": {
        "id": "yBwMOGdlO6iw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch0RJzUKOUsv",
        "outputId": "9d1ea74c-178d-4165-9926-7b83dae9809e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchscale\n",
            "  Downloading torchscale-0.3.0-py3-none-any.whl (71 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from torchscale) (2.1.0+cu118)\n",
            "Collecting fairscale==0.4.0 (from torchscale)\n",
            "  Downloading fairscale-0.4.0.tar.gz (190 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/190.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.6.13 (from torchscale)\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.6.13->torchscale) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.6.13->torchscale) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.6.13->torchscale) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->torchscale) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.13->torchscale) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.13->torchscale) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.13->torchscale) (23.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->torchscale) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->torchscale) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.6.13->torchscale) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.6.13->torchscale) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale) (2023.7.22)\n",
            "Building wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=239919 sha256=6e6990914a80a05b9a405ccf1c895c332671d26de19737b07724c28adcf4d930\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/3d/e9/3995d67ff23a09f72bba6380efb35ba97091c7932748884c41\n",
            "Successfully built fairscale\n",
            "Installing collected packages: fairscale, timm, torchscale\n",
            "Successfully installed fairscale-0.4.0 timm-0.6.13 torchscale-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchscale"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll config the model on a custom amounts of param. In our case, 134M"
      ],
      "metadata": {
        "id": "CgBWFUXlQDrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchscale.architecture.config import EncoderConfig\n",
        "from torchscale.architecture.encoder import Encoder\n",
        "\n",
        "config = EncoderConfig(\n",
        "    vocab_size=64000,\n",
        "    hidden_size=1000,\n",
        "    num_layers=10\n",
        ")\n",
        "\n",
        "model = Encoder(config)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM1praE4PCqc",
        "outputId": "d1efa98e-0a45-4fc6-8de1-2a8363a10cdb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "  (output_projection): Linear(in_features=768, out_features=64000, bias=False)\n",
            "  (layers): ModuleList(\n",
            "    (0-11): 12 x EncoderLayer(\n",
            "      (self_attn): MultiheadAttention(\n",
            "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (inner_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "      (ffn): FeedForwardNetwork(\n",
            "        (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
            "        (dropout_module): Dropout(p=0.0, inplace=False)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's calculate the params"
      ],
      "metadata": {
        "id": "EUH0ktErQKzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters in the model: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcwCRFhxP5ri",
        "outputId": "ef6a60f4-1cbb-4fc1-d997-46759c3820ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters in the model: 134300160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljnKVkykP6GM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}